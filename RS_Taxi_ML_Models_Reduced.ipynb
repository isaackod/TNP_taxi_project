{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced-feature models.\n",
    "\n",
    "We create another price prediction model that doesn't use as many of the dataset features (eg.. community area) since the information is either redundant or difficult to compute in real time for the average user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from Fair_Fare.feature_utils import load_hdf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from joblib import dump, load\n",
    "\n",
    "import xgboost as xgb\n",
    "import datetime as dt\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Plotting\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "mpl.rc('axes', labelsize=18)\n",
    "mpl.rc('xtick', labelsize=16)\n",
    "mpl.rc('ytick', labelsize=16)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TNP Dataset:\n",
    "\n",
    "Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnp = load_hdf('data/tnp_train.h5',.02)\n",
    "tnp.drop(['Pickup_Community_Area', 'Dropoff_Community_Area','l2_dist_km','x_dist_km','y_dist_km','bearing'], axis = 1, inplace = True)\n",
    "tnp.head()\n",
    "y = tnp[\"Final_Fare\"].copy()\n",
    "X = tnp.drop([\"Final_Fare\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "tnp = load_hdf('data/tnp_train.h5',15)\n",
    "# drop extra features\n",
    "tnp.drop(['Pickup_Community_Area', 'Dropoff_Community_Area','l2_dist_km','x_dist_km','y_dist_km','bearing'], axis = 1, inplace = True)\n",
    "\n",
    "y = tnp[\"Final_Fare\"].copy()\n",
    "X = tnp.drop([\"Final_Fare\"], axis = 1)\n",
    "\n",
    "\n",
    "X_train, Xv, y_train, yv = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dvalid = xgb.DMatrix(Xv.values, label=yv.values)\n",
    "dtrain = xgb.DMatrix(X_train.values, label=y_train.values)\n",
    "\n",
    "param_dist = {'max_depth': randint(low=4, high=20),\n",
    "              'n_estimators': randint(low=20, high=400),\n",
    "              'min_child_weight':randint(low=5, high=200),\n",
    "              'eta':uniform(0.15,.2),\n",
    "              'colsample_bytree':uniform(0.2,.4),\n",
    "              'subsample': uniform(0.4,.5),\n",
    "              'lambda': uniform(0.5,3.)\n",
    "             }\n",
    "\n",
    "xgb_model = xgb.XGBRegressor({\n",
    "              'booster' : 'gbtree', 'eval_metric': 'rmse','silent': 1, 'objective': 'reg:squarederror'})\n",
    "clf =  RandomizedSearchCV(xgb_model,\n",
    "                   param_dist, verbose=1,n_jobs = 6,n_iter=1000, cv=5, scoring='neg_mean_squared_error')\n",
    "clf.fit(X.values,y.values)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Full model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:10.3373\tvalid-rmse:9.59544\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[2]\ttrain-rmse:6.70169\tvalid-rmse:5.9826\n",
      "[4]\ttrain-rmse:4.78332\tvalid-rmse:4.08334\n",
      "[6]\ttrain-rmse:4.12017\tvalid-rmse:3.48801\n",
      "[8]\ttrain-rmse:3.57784\tvalid-rmse:3.03341\n",
      "[10]\ttrain-rmse:3.35888\tvalid-rmse:2.892\n",
      "[12]\ttrain-rmse:3.25541\tvalid-rmse:2.84395\n",
      "[14]\ttrain-rmse:3.20795\tvalid-rmse:2.83448\n",
      "[16]\ttrain-rmse:3.16551\tvalid-rmse:2.82939\n",
      "[18]\ttrain-rmse:3.11897\tvalid-rmse:2.83603\n",
      "[20]\ttrain-rmse:3.06205\tvalid-rmse:2.84422\n",
      "[22]\ttrain-rmse:3.03675\tvalid-rmse:2.84141\n",
      "[24]\ttrain-rmse:2.99979\tvalid-rmse:2.81795\n",
      "[26]\ttrain-rmse:2.96648\tvalid-rmse:2.80324\n",
      "[28]\ttrain-rmse:2.93414\tvalid-rmse:2.81304\n",
      "[30]\ttrain-rmse:2.9137\tvalid-rmse:2.80004\n",
      "[32]\ttrain-rmse:2.89662\tvalid-rmse:2.81526\n",
      "[34]\ttrain-rmse:2.86698\tvalid-rmse:2.80902\n",
      "[36]\ttrain-rmse:2.84091\tvalid-rmse:2.81207\n",
      "[38]\ttrain-rmse:2.81631\tvalid-rmse:2.8131\n",
      "[40]\ttrain-rmse:2.76533\tvalid-rmse:2.7734\n",
      "[42]\ttrain-rmse:2.73143\tvalid-rmse:2.77294\n",
      "[44]\ttrain-rmse:2.70818\tvalid-rmse:2.76307\n",
      "[46]\ttrain-rmse:2.68337\tvalid-rmse:2.78035\n",
      "[48]\ttrain-rmse:2.66829\tvalid-rmse:2.7915\n",
      "[50]\ttrain-rmse:2.65001\tvalid-rmse:2.78242\n",
      "[52]\ttrain-rmse:2.63571\tvalid-rmse:2.8058\n",
      "[54]\ttrain-rmse:2.62046\tvalid-rmse:2.79785\n",
      "[56]\ttrain-rmse:2.60418\tvalid-rmse:2.77544\n",
      "[58]\ttrain-rmse:2.58724\tvalid-rmse:2.77906\n",
      "[60]\ttrain-rmse:2.5627\tvalid-rmse:2.78095\n",
      "[62]\ttrain-rmse:2.54847\tvalid-rmse:2.80522\n",
      "[64]\ttrain-rmse:2.51219\tvalid-rmse:2.76651\n",
      "[66]\ttrain-rmse:2.50363\tvalid-rmse:2.74539\n",
      "[68]\ttrain-rmse:2.48112\tvalid-rmse:2.73628\n",
      "[70]\ttrain-rmse:2.46308\tvalid-rmse:2.75693\n",
      "[72]\ttrain-rmse:2.446\tvalid-rmse:2.77233\n",
      "[74]\ttrain-rmse:2.42657\tvalid-rmse:2.76612\n",
      "[76]\ttrain-rmse:2.40908\tvalid-rmse:2.77111\n",
      "[78]\ttrain-rmse:2.39166\tvalid-rmse:2.79382\n",
      "[80]\ttrain-rmse:2.37471\tvalid-rmse:2.81617\n",
      "[82]\ttrain-rmse:2.35533\tvalid-rmse:2.8275\n",
      "[84]\ttrain-rmse:2.34199\tvalid-rmse:2.81148\n",
      "[86]\ttrain-rmse:2.32811\tvalid-rmse:2.80556\n",
      "[88]\ttrain-rmse:2.31244\tvalid-rmse:2.79693\n",
      "[90]\ttrain-rmse:2.29747\tvalid-rmse:2.78018\n",
      "[92]\ttrain-rmse:2.2874\tvalid-rmse:2.78257\n",
      "[94]\ttrain-rmse:2.27739\tvalid-rmse:2.7822\n",
      "[96]\ttrain-rmse:2.26708\tvalid-rmse:2.78031\n",
      "[98]\ttrain-rmse:2.25995\tvalid-rmse:2.76482\n",
      "[100]\ttrain-rmse:2.24966\tvalid-rmse:2.76712\n",
      "[102]\ttrain-rmse:2.23669\tvalid-rmse:2.77952\n",
      "[104]\ttrain-rmse:2.22003\tvalid-rmse:2.78289\n",
      "[106]\ttrain-rmse:2.20915\tvalid-rmse:2.77613\n",
      "[108]\ttrain-rmse:2.19897\tvalid-rmse:2.77216\n",
      "[110]\ttrain-rmse:2.17728\tvalid-rmse:2.79053\n",
      "[112]\ttrain-rmse:2.17118\tvalid-rmse:2.81526\n",
      "[114]\ttrain-rmse:2.16356\tvalid-rmse:2.82124\n",
      "[116]\ttrain-rmse:2.15121\tvalid-rmse:2.83064\n",
      "Stopping. Best iteration:\n",
      "[67]\ttrain-rmse:2.48524\tvalid-rmse:2.72972\n",
      "\n",
      "Modeling RMSLE 2.72972\n",
      "Training time: 0 seconds\n"
     ]
    }
   ],
   "source": [
    "X = load_hdf('data/tnp_train.h5',20)\n",
    "X.drop(['Pickup_Community_Area', 'Dropoff_Community_Area','l2_dist_km','x_dist_km','y_dist_km','bearing'], axis = 1, inplace = True)\n",
    "\n",
    "y = X[\"Final_Fare\"].copy()\n",
    "X.drop([\"Final_Fare\"], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "X_train, Xv, y_train, yv = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dvalid = xgb.DMatrix(Xv.values, label=yv.values,feature_names = Xv.columns)\n",
    "dtrain = xgb.DMatrix(X_train.values, label=y_train.values, feature_names = X_train.columns)\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "\n",
    "xgb_pars = {'colsample_bytree': 0.439881349485437, 'eta': 0.2913248799253698, 'lambda': 1.0784417148624983, 'max_depth': 5, \n",
    "            'min_child_weight': 61, 'n_estimators': 131, 'subsample': 0.8144003761476369, 'nthread': 7, \n",
    "            'booster' : 'gbtree', 'silent': 1,\n",
    "            'eval_metric': 'rmse', 'objective': 'reg:squarederror'}\n",
    "\n",
    "\n",
    "t0 = dt.datetime.now()\n",
    "model = xgb.train(xgb_pars, dtrain, 1000, watchlist, early_stopping_rounds=50,\n",
    "                  maximize=False, verbose_eval=2)\n",
    "\n",
    "t1 = dt.datetime.now()\n",
    "print('Modeling RMSLE %.5f' % model.best_score)\n",
    "print('Training time: %i seconds' % (t1 - t0).seconds)\n",
    "\n",
    "#model.save_model(\"tnp_xgb_full\")\n",
    "\n",
    "# this is a way of saving metadata like feature names to the model\n",
    "if hasattr(model, 'feature_names'): model.set_attr(feature_names = '|'.join(model.feature_names))\n",
    "\n",
    "model.save_model(\"tnp_xgb_full_reduced_params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxi Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 200 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed: 26.6min\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed: 65.1min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed: 120.4min\n",
      "[Parallel(n_jobs=7)]: Done 800 out of 800 | elapsed: 121.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:43:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "-2.3565539554551655\n",
      "{'colsample_bytree': 0.518631511987256, 'eta': 0.2964347911729374, 'lambda': 0.6257690011998417, 'max_depth': 19, 'min_child_weight': 111, 'n_estimators': 392, 'subsample': 0.8593893731535742}\n"
     ]
    }
   ],
   "source": [
    "taxi = load_hdf('data/taxi_train.h5',1)\n",
    "# drop extra features\n",
    "taxi.drop(['Pickup_Community_Area', 'Dropoff_Community_Area','l2_dist_km','x_dist_km','y_dist_km','bearing'], axis = 1, inplace = True)\n",
    "\n",
    "y = taxi[\"Final_Fare\"].copy()\n",
    "X = taxi.drop([\"Final_Fare\"], axis = 1)\n",
    "\n",
    "\n",
    "X_train, Xv, y_train, yv = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dvalid = xgb.DMatrix(Xv.values, label=yv.values)\n",
    "dtrain = xgb.DMatrix(X_train.values, label=y_train.values)\n",
    "\n",
    "\n",
    "# parameter search\n",
    "param_dist = {'max_depth': randint(low=4, high=20),\n",
    "              'n_estimators': randint(low=20, high=400),\n",
    "              'min_child_weight':randint(low=5, high=200),\n",
    "              'eta':uniform(0.15,.2),\n",
    "              'colsample_bytree':uniform(0.2,.4),\n",
    "              'subsample': uniform(0.4,.5),\n",
    "              'lambda': uniform(0.5,3.)\n",
    "             }\n",
    "xgb_model = xgb.XGBRegressor({\n",
    "              'booster' : 'gbtree', 'eval_metric': 'rmse','silent': 1, 'objective': 'reg:squarederror'})\n",
    "clf =  RandomizedSearchCV(xgb_model,\n",
    "                   param_dist, verbose=1,n_jobs = 7,n_iter=200, cv=4, scoring='neg_mean_squared_error')\n",
    "clf.fit(X.values,y.values)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "X = load_hdf('data/taxi_train.h5',100)\n",
    "print('data loaded')\n",
    "\n",
    "y = X[\"Final_Fare\"].copy()\n",
    "X.drop(['Pickup_Community_Area', 'Dropoff_Community_Area','l2_dist_km','x_dist_km','y_dist_km','bearing'], axis = 1, inplace = True)\n",
    "X.drop([\"Final_Fare\"], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "X_train, Xv, y_train, yv = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dvalid = xgb.DMatrix(Xv.values, label=yv.values,feature_names = Xv.columns)\n",
    "dtrain = xgb.DMatrix(X_train.values, label=y_train.values, feature_names = X_train.columns)\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "\n",
    "\n",
    "xgb_pars = {'colsample_bytree': 0.518631511987256, 'eta': 0.2964347911729374, 'lambda': 0.6257690011998417, 'max_depth': 19, \n",
    "            'min_child_weight': 111, 'n_estimators': 392, 'subsample': 0.8593893731535742, 'nthread': 6, \n",
    "            'booster' : 'gbtree', 'silent': 1,\n",
    "            'eval_metric': 'rmse', 'objective': 'reg:squarederror'}\n",
    "\n",
    "\n",
    "t0 = dt.datetime.now()\n",
    "model = xgb.train(xgb_pars, dtrain, 1000, watchlist, early_stopping_rounds=50,\n",
    "                  maximize=False, verbose_eval=5)\n",
    "\n",
    "t1 = dt.datetime.now()\n",
    "print('Modeling RMSLE %.5f' % model.best_score)\n",
    "print('Training time: %i seconds' % (t1 - t0).seconds)\n",
    "\n",
    "# this is a way of saving metadata like feature names to the model\n",
    "if hasattr(model, 'feature_names'): model.set_attr(feature_names = '|'.join(model.feature_names))\n",
    "\n",
    "model.save_model(\"taxi_xgb_full_reduced_params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Trip_Seconds',\n",
       " 'Trip_Miles',\n",
       " 'Pickup_Centroid_Latitude',\n",
       " 'Pickup_Centroid_Longitude',\n",
       " 'Dropoff_Centroid_Latitude',\n",
       " 'Dropoff_Centroid_Longitude',\n",
       " 'vel_mph',\n",
       " 'bAirport',\n",
       " 'day_of_wk',\n",
       " 'hour']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
